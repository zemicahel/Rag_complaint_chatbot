{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca76f381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled Dataset Shape: (15000, 20)\n",
      "Product Distribution in Sample:\n",
      " Product\n",
      "Checking or savings account                           0.328733\n",
      "Credit card or prepaid card                           0.254600\n",
      "Money transfer, virtual currency, or money service    0.227667\n",
      "Credit card                                           0.189000\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the cleaned data from Task 1\n",
    "df = pd.read_csv('../data/processed/filtered_complaints.csv')\n",
    "\n",
    "# Create a stratified sample (15,000 records)\n",
    "# This ensures \"Money Transfers\" (smaller category) is still well-represented \n",
    "# relative to \"Credit Cards\" (larger category)\n",
    "sample_size = 15000\n",
    "df_sample, _ = train_test_split(\n",
    "    df, \n",
    "    train_size=sample_size, \n",
    "    stratify=df['Product'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Sampled Dataset Shape: {df_sample.shape}\")\n",
    "print(\"Product Distribution in Sample:\\n\", df_sample['Product'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ba10bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 41457 total chunks from 15000 complaints.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# We choose 500 chars (~100 words) with a 50 char overlap\n",
    "# Overlap ensures that context isn't lost if a sentence is cut in half\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "# Function to process the dataframe into chunks with metadata\n",
    "def create_chunks(df):\n",
    "    chunked_docs = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # Create chunks for this specific narrative\n",
    "        chunks = text_splitter.split_text(row['cleaned_narrative'])\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # Store the text and the metadata needed to trace it back\n",
    "            chunked_docs.append({\n",
    "                \"page_content\": chunk,\n",
    "                \"metadata\": {\n",
    "                    \"complaint_id\": row['Complaint ID'],\n",
    "                    \"product\": row['Product'],\n",
    "                    \"company\": row['Company'],\n",
    "                    \"chunk_index\": i\n",
    "                }\n",
    "            })\n",
    "    return chunked_docs\n",
    "\n",
    "docs = create_chunks(df_sample)\n",
    "print(f\"Created {len(docs)} total chunks from {len(df_sample)} complaints.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5448db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Indexing... this may take 5-10 minutes depending on CPU.\n",
      "Vector Store saved at ../vector_store/complaints_db\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# 1. Initialize the Embedding Model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model_kwargs = {'device': 'cpu'} # Change to 'cuda' if using a GPU\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# 2. Create and Persist the Vector Store\n",
    "# This will save the database into the 'vector_store/' folder\n",
    "persist_directory = '../vector_store/complaints_db'\n",
    "\n",
    "# Extract text and metadata for Chroma\n",
    "texts = [doc['page_content'] for doc in docs]\n",
    "metadatas = [doc['metadata'] for doc in docs]\n",
    "\n",
    "print(\"Starting Indexing... this may take 5-10 minutes depending on CPU.\")\n",
    "\n",
    "vector_db = Chroma.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embeddings,\n",
    "    metadatas=metadatas,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "print(f\"Vector Store saved at {persist_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f969d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "Product: Credit card or prepaid card\n",
      "Content: for approimately minutes while someone worked on my issue was told that this is an issue for my bank to fi and was hung up on continues to tell me that i need to call my bank and that because the char...\n",
      "\n",
      "Result 2:\n",
      "Product: Credit card or prepaid card\n",
      "Content: i had an issue with this company beginning in i used my card to purchase something online i then received a bill with an unauthorized charge on it i called the company and disputed the charge they sta...\n",
      "\n",
      "Result 3:\n",
      "Product: Credit card\n",
      "Content: the credit card company on to investigate the charge through their online how can i dispute a charge process when i called their customer service staff according to the instructions of their online pr...\n"
     ]
    }
   ],
   "source": [
    "# Test if the search works\n",
    "query = \"How do I dispute an unauthorized credit card charge?\"\n",
    "results = vector_db.similarity_search(query, k=3)\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(f\"Product: {res.metadata['product']}\")\n",
    "    print(f\"Content: {res.page_content[:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
